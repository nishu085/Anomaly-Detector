{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91774ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pande\\Downloads\\Project_2023\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba75d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f43821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5e837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %apt-get update && apt-get install libgl1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bca680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.1.0->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pande\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59721dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11e24bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Normal3586.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Iterate over the dataset\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Perform training steps here\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Placeholder for training steps\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     45\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Load corresponding label\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Adjust labels if data augmentation is applied\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Normal3586.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_root = \"C:/Users/pande/Downloads/Project_2023/Dataset\"  # Adjust this path as per your dataset structure\n",
    "\n",
    "# Define the transformations for data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Custom dataset class to load images and adjust labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load filenames and labels\n",
    "        self.image_dir = os.path.join(root_dir, 'images', 'train')  # Adjust this according to your dataset structure\n",
    "        self.label_dir = os.path.join(root_dir, 'labels', 'train')  # Adjust this according to your dataset structure\n",
    "        self.filenames = os.listdir(self.image_dir)\n",
    "        self.labels = {}  # Assuming labels are stored in a dictionary\n",
    "\n",
    "        # Load labels from file or database\n",
    "        self.load_labels()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.image_dir, self.filenames[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Load corresponding label\n",
    "        label = self.labels[self.filenames[idx]]\n",
    "\n",
    "        # Adjust labels if data augmentation is applied\n",
    "        if self.transform:\n",
    "            label = self.adjust_labels(label, image.shape[1], image.shape[2])\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def load_labels(self):\n",
    "        # Load labels from file or database\n",
    "        pass  # Implement this function to load labels\n",
    "\n",
    "    def adjust_labels(self, label, img_width, img_height):\n",
    "        # Adjust bounding box coordinates based on image transformations\n",
    "        class_name, x_min, y_min, x_max, y_max = label.split()\n",
    "        x_min, y_min, x_max, y_max = float(x_min), float(y_min), float(x_max), float(y_max)\n",
    "\n",
    "        # Example: Scale coordinates based on image size\n",
    "        # Adjusting for resized image (assuming original image size is 224x224)\n",
    "        x_min = x_min * img_width / 224\n",
    "        y_min = y_min * img_height / 224\n",
    "        x_max = x_max * img_width / 224\n",
    "        y_max = y_max * img_height / 224\n",
    "\n",
    "        return f\"{class_name} {x_min} {y_min} {x_max} {y_max}\"  # Adjusted label format\n",
    "\n",
    "# Instantiate the dataset with augmentation\n",
    "dataset = CustomDataset(root_dir=dataset_root, transform=train_transforms)\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate over the dataset\n",
    "for images, labels in train_loader:\n",
    "    # Perform training steps here\n",
    "    pass  # Placeholder for training steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6d56b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=models/yolov5s.yaml, data=dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=60, imgsz=224, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "fatal: cannot change to '/workspace/Nishu': No such file or directory\n",
      "YOLOv5 🚀 2023-12-18 Python-3.8.10 torch-2.1.2+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40536MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     43152  models.yolo.Detect                      [11, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7049296 parameters, 7049296 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/Nishu Pandey/Project_2023/Main_Dataset/train/labels..\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspace/Nishu Pandey/Project_2023/Main_Dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/Nishu Pandey/Project_2023/Main_Dataset/val/labels... 45\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspace/Nishu Pandey/Project_2023/Main_Dataset/val/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.88 anchors/target, 0.726 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 4929 of 17998 labels are <3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 13070 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8118: 100%|████\u001b[0m\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.7260 best possible recall, 4.32 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=224, metric_all=0.292/0.590-mean/best, past_thr=0.527-mean: 17,16, 25,24, 39,36, 57,58, 116,66, 90,92, 95,149, 146,121, 191,189\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ⚠️ (original anchors better than new anchors, proceeding with original anchors)\n",
      "Plotting labels to runs/train/exp13/labels.jpg... \n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp13\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49      1.63G     0.0918    0.01038     0.0564         70        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.674     0.0373     0.0185    0.00737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49      2.01G    0.07371    0.01081    0.04356         67        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.254       0.13     0.0567       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49      2.01G    0.07354    0.01072    0.03956         77        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.435      0.129      0.075     0.0289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49      2.01G    0.07243    0.01067    0.03778         72        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.437      0.135     0.0818     0.0341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49      2.01G    0.06998    0.01074    0.03496         67        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.407      0.171      0.116     0.0411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49      2.01G    0.06904    0.01069    0.03344         77        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.348      0.224      0.124     0.0476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49      2.01G    0.06744    0.01067    0.03209         79        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.394      0.209      0.126     0.0528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49      2.01G    0.06682    0.01052    0.03126         80        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.397      0.234      0.155     0.0645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49      2.01G    0.06578    0.01048    0.03053         56        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.514      0.248      0.193     0.0907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49      2.01G    0.06492    0.01041    0.02963         77        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.448      0.237      0.185     0.0821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49      2.01G    0.06501    0.01039    0.02889         66        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.436      0.247      0.192     0.0845\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49      2.01G    0.06412    0.01046    0.02846         62        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.424      0.269      0.188     0.0802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49      2.01G    0.06384    0.01043    0.02743         74        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.499      0.251      0.199     0.0816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49      2.01G    0.06322    0.01038    0.02729         69        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.462      0.281      0.206     0.0953\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49      2.01G    0.06276    0.01034    0.02674         83        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.472      0.286      0.219     0.0998\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49      2.01G     0.0623    0.01032    0.02624         80        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505       0.47      0.277      0.213     0.0975\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49      2.01G    0.06193    0.01041    0.02566         73        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505       0.48      0.313      0.234      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49      2.01G    0.06161    0.01039    0.02563         80        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.477      0.312      0.229       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49      2.01G    0.06153    0.01026     0.0251         79        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.465      0.315      0.242      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49      2.01G    0.06099    0.01025    0.02457         73        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.496      0.334      0.253      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49      2.01G    0.06055    0.01022    0.02401         74        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.495      0.335      0.255      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49      2.01G    0.06037    0.01017    0.02401         55        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.514      0.324      0.245      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49      2.01G    0.06028    0.01021    0.02401         64        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505        0.5       0.32      0.248      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49      2.01G    0.05978    0.01026    0.02353         61        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.499      0.346      0.265      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49      2.01G    0.05943    0.01014    0.02362         71        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.519      0.349      0.268      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49      2.01G    0.05934    0.01021    0.02284         68        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.517      0.347      0.271      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49      2.01G    0.05909    0.01013    0.02268         70        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.513      0.367      0.275      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49      2.01G    0.05841    0.01013    0.02213         64        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.509      0.367      0.275      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49      2.01G    0.05846    0.01004    0.02202         70        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.513      0.353       0.27      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49      2.01G    0.05799    0.01016    0.02182         80        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.499       0.37      0.274      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49      2.01G    0.05757    0.01014    0.02137         73        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.525      0.366       0.28      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49      2.01G    0.05725    0.01018    0.02093         81        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.515      0.371      0.285      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49      2.01G     0.0574    0.01011    0.02094         70        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.511      0.374      0.281      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49      2.01G    0.05664    0.01011    0.02043         67        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.517      0.372      0.283      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49      2.01G    0.05675    0.01013    0.02034         61        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.521      0.375      0.281      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49      2.01G    0.05642    0.01004    0.01997         64        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.525      0.388      0.286      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49      2.01G     0.0564   0.009974    0.01958         62        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505       0.52      0.383      0.286      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49      2.01G    0.05568    0.01004    0.01915         86        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.525      0.394      0.295      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49      2.01G    0.05554   0.009931    0.01878         84        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.523      0.388      0.285      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49      2.01G    0.05539   0.009931    0.01823         69        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505       0.52      0.382      0.287      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49      2.01G    0.05516   0.009994    0.01814         64        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.528      0.385      0.294       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49      2.01G    0.05454   0.009959    0.01775         61        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.527      0.395      0.297      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49      2.01G    0.05377   0.009941    0.01774         84        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.525      0.392      0.295      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49      2.01G    0.05397   0.009909    0.01707         69        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.517      0.393      0.297      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49      2.01G    0.05344   0.009887    0.01703         74        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.521      0.394      0.297      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49      2.01G    0.05301   0.009848     0.0166         86        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.515      0.397      0.295      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49      2.01G    0.05276    0.00981    0.01651         65        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.518      0.398      0.295      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49      2.01G    0.05232   0.009741    0.01587         80        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.516        0.4      0.297      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49      2.01G    0.05182   0.009765    0.01534         74        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.516      0.402      0.297      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49      2.01G    0.05195   0.009804    0.01553         73        224: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.514      0.402      0.296      0.154\n",
      "\n",
      "50 epochs completed in 0.526 hours.\n",
      "Optimizer stripped from runs/train/exp13/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp13/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp13/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 157 layers, 7039792 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       4505       4505      0.516      0.403      0.297      0.153\n",
      "                Normal       4505       1233          1          0          0          0\n",
      "              Polypoid       4505        649      0.294      0.242      0.195      0.082\n",
      "          Diverticulum       4505         11          1          0     0.0716     0.0392\n",
      "              Erythema       4505        204      0.342      0.402      0.258      0.112\n",
      "      Lymphangiectasia       4505        122      0.379      0.615      0.336      0.126\n",
      "        Lymph follicle       4505       1358      0.339     0.0839      0.106     0.0374\n",
      "              Bleeding       4505        174      0.475      0.603      0.497      0.271\n",
      "              Erythema       4505        183      0.535      0.727       0.57      0.348\n",
      "                Venous       4505        109      0.299      0.413      0.241     0.0902\n",
      "SMT(Submucosal tumors)       4505         89      0.664      0.831      0.701       0.46\n",
      "          Angioectasia       4505        373      0.351      0.517      0.292      0.121\n",
      "Results saved to \u001b[1mruns/train/exp13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img-size 224 --batch-size 60 --epochs 50 --data dataset.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e213fa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e692fa53cc0a8654\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e692fa53cc0a8654\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='runs/train/exp2/test_batch2_pred.jpg', width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416994db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python detect.py --source runs/train/exp/testimg.jpg --weights runs/train/exp/weights/best.pt --conf 0.25\n",
    "\n",
    "!python detect.py --source runs/train/exp2/a.jpg --weights best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='runs/detect/exp4/a.jpg', width=416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb72fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_results \n",
    "plot_results(save_dir='runs/train/exp2')  # plot results.txt as results.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
